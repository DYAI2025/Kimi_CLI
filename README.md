# Kimi_CLI
=======
# ğŸ¤– Kimi K2 Instruct Client

VollstÃ¤ndiger Client fÃ¼r **Kimi K2 Instruct** - das State-of-the-Art MoE Modell mit 1 Trillion Parametern (32B aktiviert).

## âœ¨ Features

- **ğŸ¯ Echtes Kimi K2 Instruct Modell** Ã¼ber Moonshot AI
- **ğŸ’» CLI Chat** - Interaktive Kommandozeilen-OberflÃ¤che
- **ğŸ–¥ï¸ GUI Chat** - Moderne grafische BenutzeroberflÃ¤che
- **âš¡ Streaming Support** - Live-Antworten
- **ğŸ› ï¸ Tool Calling** - Function Calling UnterstÃ¼tzung
- **ğŸ“‹ 128K Kontext** - Verarbeitung umfangreicher Dokumente
- **ğŸ›ï¸ VollstÃ¤ndige Kontrolle** - Temperature, Max Tokens, System Prompts

## ğŸš€ Quick Start

### 1. API-Key einrichten

1. **Erstellen Sie einen API-Key bei Moonshot AI:**
   ```
   https://platform.moonshot.ai
   ```

2. **Setzen Sie den API-Key in der `.env`-Datei:**
   ```bash
   MOONSHOT_API_KEY=sk-your_api_key_here
   ```

### 2. Starten

**One-Click-Start (empfohlen):**
```bash
./start_kimi.command
```

**Oder manuell:**
```bash
# CLI Chat (Terminal-basiert)
python3 kimi_chat.py

# Standard GUI (einfache OberflÃ¤che)
python3 kimi_gui.py

# ğŸ¨ Moderne GUI (mit TTS/STT, groÃŸe Schrift)
python3 kimi_gui_modern.py

# API-Information anzeigen
python3 api_info.py

# Client-Test ausfÃ¼hren
python3 kimi_client.py
```

## ğŸ“‹ Verwendung

### CLI Chat

```
ğŸ¤– Willkommen bei Kimi K2 Instruct!

> Hallo Kimi! Kannst du mir beim Programmieren helfen?
```

**VerfÃ¼gbare Kommandos:**
- `model [name]` - Modell wechseln
- `temp [0.0-1.0]` - Temperature setzen
- `tokens [anzahl]` - Max Tokens setzen
- `stream` - Streaming ein/aus
- `system [prompt]` - System Prompt setzen
- `clear` - Chat-Verlauf lÃ¶schen
- `info` - Modell-Informationen
- `help` - Hilfe anzeigen
- `quit` / `q` / `exit` - Beenden

### GUI Chat

**Standard GUI:**
- âš™ï¸ **Konfiguration** - Modell, Temperature, Max Tokens
- ğŸ’¬ **Chat-Bereich** - Farbkodierte Nachrichten
- ğŸ›ï¸ **System Prompt** - Anpassbare Rolle fÃ¼r Kimi
- ğŸ’¾ **Chat-Verwaltung** - Speichern/Laden von GesprÃ¤chen
- âŒ¨ï¸ **TastenkÃ¼rzel** - Ctrl+Enter zum Senden, F1 fÃ¼r Hilfe

**ğŸ¨ Moderne GUI (Empfohlen):**
- ğŸ”¤ **GroÃŸe Schrift** - Gut lesbare 14-16pt Fonts
- ğŸ¨ **Farbenfrohes Design** - Modernes, minimalistisches UI
- ğŸ¤ **Speech-to-Text** - Spracheingabe per Mikrofon
- ğŸ”Š **Text-to-Speech** - Vorlesen der AI-Antworten
- âš¡ **Live-Streaming** - Antworten erscheinen in Echtzeit
- ğŸ“± **Responsive** - Skalierbare OberflÃ¤che
- ğŸ›ï¸ **Live-Konfiguration** - Modell & Temperature ohne Neustart Ã¤ndern

### Text-to-Speech mit ElevenLabs

1. Erstellen Sie einen API-Key auf <https://elevenlabs.io> und tragen Sie ihn in der `.env` ein:
   ```bash
   ELEVEN_API_KEY=your_elevenlabs_key
   ```
2. Optional kann die bevorzugte Stimme direkt per Voice ID gesetzt werden:
   ```bash
   ELEVEN_VOICE_ID=your_voice_id
   ```
3. In der modernen GUI lÃ¤sst sich die Voice ID auch zur Laufzeit im Feld **Voice ID** Ã¤ndern.


### Programmierung (Python)

```python
from kimi_client import KimiClient

# Client initialisieren
kimi = KimiClient()

# Einfacher Chat
response = kimi.simple_chat("Hallo Kimi!")
print(response)

# Chat mit Verlauf
response = kimi.chat_with_history("Was ist Python?")
print(response)

# Streaming Chat
for chunk in kimi.chat_stream("ErklÃ¤re Machine Learning"):
    print(chunk, end="", flush=True)

# Tool Calling
tools = [{
    "type": "function",
    "function": {
        "name": "get_weather",
        "description": "Retrieve weather information",
        "parameters": {
            "type": "object",
            "required": ["city"],
            "properties": {
                "city": {"type": "string", "description": "City name"}
            }
        }
    }
}]

result = kimi.tool_call("What's the weather in Berlin?", tools)
print(result)
```

## ï¿½ï¿½ Konfiguration

### Modelle

- **`Kimi-K2-Instruct`** - Hauptmodell (empfohlen)
- **`meta-llama/Llama-3.1-8B-Instruct-Turbo`** - Alternative fÃ¼r schnelle Antworten
- **`meta-llama/Llama-3.1-70B-Instruct-Turbo`** - Hochleistungsmodell

### Parameter

- **Temperature:** `0.0-1.0` (empfohlen: `0.6`)
- **Max Tokens:** Bis zu `128K` Token
- **Context Length:** `128K` Token

### System Prompts

```python
# Standard
"You are Kimi, an AI assistant created by Moonshot AI."

# Spezialisiert fÃ¼r Coding
"You are Kimi, a world-class programming assistant. Help with code, debugging, and architecture."

# Deutscher Assistent
"Du bist Kimi, ein hilfreicher KI-Assistent. Antworte immer auf Deutsch."
```

## ğŸ› ï¸ Tool Calling

Kimi K2 Instruct unterstÃ¼tzt natives Function Calling:

```python
def get_weather(city: str) -> dict:
    return {"weather": "Sunny", "temperature": "22Â°C"}

tools = [{
    "type": "function",
    "function": {
        "name": "get_weather",
        "description": "Get weather for a city",
        "parameters": {
            "type": "object",
            "required": ["city"],
            "properties": {
                "city": {"type": "string", "description": "Name of the city"}
            }
        }
    }
}]

result = kimi.tool_call("What's the weather in Tokyo?", tools)

if result["finish_reason"] == "tool_calls":
    for tool_call in result["tool_calls"]:
        function_name = tool_call.function.name
        arguments = json.loads(tool_call.function.arguments)
        # FÃ¼hre die Funktion aus
        result = get_weather(**arguments)
```

## ğŸ“Š Modell-Spezifikationen

| Eigenschaft | Wert |
|-------------|------|
| **Parameter** | 1 Trillion (32B aktiviert) |
| **Architektur** | Mixture-of-Experts (MoE) |
| **Kontext** | 128K Token |
| **Spezialisierung** | Coding, Reasoning, Tool Use |
| **Provider** | Moonshot AI |
| **Training** | 15.5T Token mit Muon Optimizer |

## ğŸ¯ AnwendungsfÃ¤lle

### Coding & Development
- **Code-Generierung** - VollstÃ¤ndige Programme
- **Debugging** - Fehleranalyse und -behebung
- **Code Review** - QualitÃ¤tsprÃ¼fung
- **Architektur** - System-Design

### Reasoning & Analyse
- **Mathematik** - Komplexe Berechnungen
- **Logik** - ProblemlÃ¶sung
- **Analyse** - Datenauswertung
- **Forschung** - Literatur-Review

### Tool Use & Automation
- **API-Integration** - Externe Services
- **Workflow-Automation** - Prozess-Optimierung
- **Data Processing** - Datenverarbeitung
- **System-Integration** - Tool-Orchestrierung

## ğŸ” Fehlerbehebung

### API-Key Probleme

```bash
âŒ Fehler: Bitte setzen Sie MOONSHOT_API_KEY in der .env-Datei
```

**LÃ¶sung:**
1. Besuchen Sie https://platform.moonshot.ai
2. Erstellen Sie einen neuen API-Key
3. Setzen Sie ihn in der `.env`-Datei:
   ```
   MOONSHOT_API_KEY=sk-your_actual_api_key_here
   ```

### Dependencies

```bash
âŒ Fehler beim Installieren der Requirements
```

**LÃ¶sung:**
```bash
pip3 install python-dotenv pydantic openai
```

### GUI Probleme

Wenn die GUI nicht startet:
```bash
# macOS
brew install python-tk

# Ubuntu/Debian
sudo apt-get install python3-tk

# Windows
# Meist bereits enthalten
```

## ğŸ“š API-Referenz

### KimiClient Klasse

```python
class KimiClient:
    def __init__(self, model: str = "moonshotai/Kimi-K2-Instruct", 
                 temperature: float = 0.6, max_tokens: int = 4096)
    
    def simple_chat(self, message: str) -> str
    def chat_with_history(self, message: str, system_prompt: Optional[str] = None) -> str
    def chat_stream(self, message: str, system_prompt: Optional[str] = None) -> Iterator[str]
    def tool_call(self, message: str, tools: List[Dict[str, Any]]) -> Dict[str, Any]
    def clear_history(self)
    def get_models(self) -> List[str]
    def set_model(self, model: str)
    def get_model_info(self) -> Dict[str, Any]
```

## ğŸ†š Benchmark-Ergebnisse

Kimi K2 Instruct fÃ¼hrt in vielen Benchmarks:

| Benchmark | Kimi K2 | DeepSeek-V3 | GPT-4.1 |
|-----------|---------|-------------|---------|
| **LiveCodeBench** | **53.7%** | 46.9% | 44.7% |
| **SWE-bench Verified** | **65.8%** | 38.8% | 54.6% |
| **MMLU** | **89.5%** | 89.4% | 90.4% |
| **AIME 2024** | **69.6%** | 59.4% | 46.5% |
| **ZebraLogic** | **89.0%** | 84.0% | 58.5% |


## ğŸ› ï¸ Kimi K2 Agent

Neue Agent-Klasse `KimiK2Agent` mit direktem Zugriff auf das Execution Toolkit. Befehle aus einer Plan-Datei werden sequenziell ausgefÃ¼hrt.

## ğŸŒŸ Innovationsideen

1. **Multimodaler Upload** - Bilder oder PDFs direkt im Chatfenster analysieren lassen.
2. **Offline-Modus** - Kleine Sprachmodelle lokal ausfÃ¼hren, falls keine Internetverbindung besteht.
3. **Workflow-Vorlagen** - Vorgefertigte Befehlssequenzen speichern und als Makros starten.
## ğŸ“„ Lizenz

Modified MIT License - Siehe [Hugging Face Modell-Seite](https://huggingface.co/moonshotai/Kimi-K2-Instruct)

## ğŸ¤ Support

- **Moonshot AI Docs:** https://platform.moonshot.ai
- **Kimi K2 Model Card:** https://huggingface.co/moonshotai/Kimi-K2-Instruct
- **Issues:** Erstellen Sie ein Issue in diesem Repository

---

**Kimi K2 Instruct** - Agentic Intelligence fÃ¼r die Zukunft ğŸš€
